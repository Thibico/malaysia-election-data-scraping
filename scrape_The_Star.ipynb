{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import required libraries\n",
    "import re\n",
    "import pandas as pd\n",
    "from requests_html import HTMLSession\n",
    "from requests_html import AsyncHTMLSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = \"https://election.thestar.com.my/\"\n",
    "session = HTMLSession()\n",
    "r = session.get(main_url)\n",
    "\n",
    "## Previous testing individually\n",
    "# r = session.get('https://election.thestar.com.my/ft.html')\n",
    "# r = session.get('https://election.thestar.com.my/johor.html')\n",
    "# r = session.get('https://election.thestar.com.my/kelantan.html')\n",
    "# r = session.get('https://election.thestar.com.my/perak.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_svg(url: str,region):\n",
    "    '''\n",
    "    scraping svg\n",
    "    We need to use asynchronous function because map svg is rendered by js\n",
    "    '''\n",
    "    asession = AsyncHTMLSession()\n",
    "    r = await asession.get(url)\n",
    "    await r.html.arender(sleep=5)\n",
    "    tab_content = r.html.find(\".tab-content\",first=True)\n",
    "    tab_panels = tab_content.find(\".tab-pane\")\n",
    "    print(\"Length of tab_panels: \",len(tab_panels))\n",
    "    for a in range(len(tab_panels)):\n",
    "        tab_attributes = tab_panels[a].attrs\n",
    "        tab_id = tab_attributes.get(\"id\")\n",
    "        if tab_id == 'f1':\n",
    "            tab_name = \"parliament\"\n",
    "            svg_data = tab_panels[0].find(\"#svgP\",first=True).html\n",
    "            # print(type(svg_data))\n",
    "            if svg_data != None:\n",
    "                ## Convert string into byte \n",
    "                svg_byte = bytes(svg_data, encoding=\"utf-8\")\n",
    "                given_name = region + \"_\" + tab_name\n",
    "                with open(f'./svgs/{given_name}.svg', 'wb+') as f:\n",
    "                    f.write(svg_byte)\n",
    "                print(f\"{given_name} svg write!\")\n",
    "            else:\n",
    "                print(\"Not found svg for Parliment\")\n",
    "            \n",
    "        if tab_id =='f2':\n",
    "            tab_name = \"state\"\n",
    "            svg_data = tab_panels[1].find(\"#svgN\", first=True).html\n",
    "            if svg_data != None:\n",
    "                ## Convert string into byte \n",
    "                svg_byte = bytes(svg_data, encoding=\"utf-8\")\n",
    "                given_name = region + \"_\" + tab_name\n",
    "                with open(f'./svgs/{given_name}.svg', 'wb+') as f:\n",
    "                    f.write(svg_byte)\n",
    "                print(f\"{given_name} svg write!\")\n",
    "            else:\n",
    "                print(\"Not found svgN for State\")\n",
    "    await asession.close()\n",
    "    # return svg_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## testing with one url\n",
    "test_url = \"https://election.thestar.com.my/johor.html\"\n",
    "await get_svg(test_url,'Johor')\n",
    "'''\n",
    "'''\n",
    "## Testing block to convert string to bytes\n",
    "#convert string to byte\n",
    "svg_byte = bytes(data_web, \"utf-8\")\n",
    "with open('test.svg','wb+') as f:\n",
    "    f.write(svg_byte)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Scraping data for looping webpages\n",
    "state = r.html.find(\"ul.state-list\", first=True)\n",
    "state_list = state.find(\"a\")\n",
    "for i in range(len(state_list)):\n",
    "    list_attrs = state_list[i].attrs\n",
    "    # print(list_attrs)\n",
    "    urls = main_url + list_attrs.get('href')\n",
    "    state_name = state_list[i].text.replace(\" \",\"\")\n",
    "    print(state_name,\"|\",urls)\n",
    "    new_session = HTMLSession()\n",
    "    ns = new_session.get(urls)\n",
    "    # print(ns.url)\n",
    "    # print(ns.status_code)\n",
    "    if ns.status_code == 200:\n",
    "        ## saving svg files for each parliment & state map\n",
    "        await get_svg(urls,state_name)\n",
    "        print(f\"Scraping SVG for {state_name} done!\")\n",
    "        \n",
    "        ## scraping results & facts(demographic) data\n",
    "        # scrape_panels(ns, state_name)\n",
    "    else:\n",
    "        print(\"Connection error!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scraping function to get results & demographic data\n",
    "def scrape_panels(conn, region):\n",
    "    '''\n",
    "    Scraping function to get results & demographic data\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    tab_content = conn.html.find(\".tab-content\")\n",
    "    \n",
    "    ## Only ft & sarawak pages will have one tab_panel , others length will be 2\n",
    "    tab_panels = tab_content[0].find(\".tab-pane\")\n",
    "    # print(\"Tab Panels (P or S):{}\".format(len(tab_panels)))\n",
    "    for a in range(len(tab_panels)):\n",
    "        ## Divide parliament or state tabs\n",
    "        tab_attributes = tab_panels[a].attrs\n",
    "        tab_id = tab_attributes.get(\"id\")\n",
    "        if tab_id == 'f1':\n",
    "            tab_name = \"parliament\"\n",
    "            \n",
    "            ## Getting Parliament > Result , Parliament > Facts(demographic)\n",
    "            p_result,p_fact = scrape_data(tab_panels[0],tab_name)\n",
    "            p_result['state_region'] = region\n",
    "            p_fact['state_region'] = region\n",
    "            \n",
    "            ## should I export csv under this function?\n",
    "            ## Export with custom name\n",
    "            given_name = region + \"_\" + tab_name\n",
    "            p_result.to_csv(f'./data/raw/the_star/{given_name}_result.csv')\n",
    "            p_fact.to_csv(f'./data/raw/the_star/{given_name}_fact.csv')\n",
    "            \n",
    "        if tab_id == 'f2':\n",
    "            tab_name = \"state\"\n",
    "       \n",
    "            ## Getting State > Result , State > Facts(demographic)\n",
    "            s_result,s_fact = scrape_data(tab_panels[1],tab_name)\n",
    "            s_result['state_region'] = region\n",
    "            s_fact['state_region'] = region\n",
    "            \n",
    "            ## Export with custom name\n",
    "            given_name = region + \"_\" + tab_name\n",
    "            s_result.to_csv(f'./data/raw/the_star/{given_name}_result.csv')\n",
    "            s_fact.to_csv(f'./data/raw/the_star/{given_name}_fact.csv')\n",
    "        # print(tab_name)\n",
    "        # print(f\"Tab-Panel-{a}\")\n",
    "        # print(\"---xxx---\")\n",
    "        \n",
    "    ## If I exported CSVs , I don't need to return dfs.\n",
    "    if len(tab_panels) == 1:\n",
    "        ## Returning parliament result & facts(demographic) data\n",
    "        print(\"Parliament only data\")\n",
    "        # return p_result,p_fact\n",
    "    elif len(tab_panels) == 2:\n",
    "        ## Returning both perliment+state result & facts(demographic) data\n",
    "        print(\"Parliament + State data\")\n",
    "        # return p_result,p_fact,s_result,s_fact\n",
    "    else:\n",
    "        print(\"No Data found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(tab_panel,tab_name):\n",
    "    '''\n",
    "    scrape data under .winner-list > multiple .panel\n",
    "    '''\n",
    "    panels = tab_panel.find(\".panel\")\n",
    "    # print(len(panels))\n",
    "    result_data = []\n",
    "    fact_data = []\n",
    "        \n",
    "    for i in range(len(panels)):\n",
    "        ## Inside .panel-heading\n",
    "        header = panels[i].find(\"h4.panel-title\")[0].text.split(\" \")\n",
    "        pcode = header[0]\n",
    "        pname = ' '.join(header[1:])\n",
    "        print(pcode,\"|\",pname)\n",
    "        \n",
    "        ## Inside .panel-body \n",
    "        wrapper = panels[i].find(\".progress-wrapper\")\n",
    "        # print(len(wrapper))\n",
    "        # print(\"---xx---\")\n",
    "        \n",
    "        for j in range(len(wrapper)):\n",
    "            results_by_territories = {}\n",
    "            name = wrapper[j].find(\"p.name-candidate\")[0].text\n",
    "            # print(name)\n",
    "            number_of_voters = wrapper[j].find(\".number-of-voters\")[0].text\n",
    "            # print(number_of_voters)\n",
    "            results_by_territories[\"name\"] = name\n",
    "            results_by_territories[\"number_of_voters\"] = number_of_voters\n",
    "            \n",
    "            ## Adding pcode,pname from .panel-heading\n",
    "            results_by_territories[\"panel_code\"]= pcode\n",
    "            results_by_territories[\"panel_name\"]= pname\n",
    "            \n",
    "            ## Adding tab name (Parliament or State)\n",
    "            results_by_territories[\"tab\"] = tab_name\n",
    "            result_data.append(results_by_territories)\n",
    "        \n",
    "        \n",
    "        blue_box = panels[i].find(\".blue-box-info\")\n",
    "        \n",
    "        facts = {}\n",
    "        if blue_box != None:\n",
    "            # print(\"Found Blue_box!\")\n",
    "            ## Do I need to find \"voters-vote\" class?\n",
    "            info = blue_box[0].find(\"p\")\n",
    "            num_regex = re.compile(r'[\\d,\\.\\s\\(%\\)]+')\n",
    "            registered_voters = ''.join(num_regex.findall(info[0].text)).strip()\n",
    "            majority = ''.join(num_regex.findall(info[1].text)).strip()\n",
    "            spoilt_votes = ''.join(num_regex.findall(info[2].text)).strip()\n",
    "            unreturned_votes = ''.join(num_regex.findall(info[3].text)).strip()\n",
    "            voter_turnout = ''.join(num_regex.findall(info[4].text)).strip()\n",
    "            demographics = info[5].text\n",
    "            # print(registered_voters,\"|\",majority,\"|\",spoilt_votes,\"|\",unreturned_votes,\"|\",voter_turnout)\n",
    "            # print(demographics)\n",
    "    \n",
    "            facts['registered_voters'] = registered_voters\n",
    "            facts['majority'] = majority\n",
    "            facts['spoilt_votes'] = spoilt_votes\n",
    "            facts['unreturned_votes']= unreturned_votes\n",
    "            facts['voter_turnout'] = voter_turnout\n",
    "            facts['demographics']= demographics\n",
    "            \n",
    "            ## Adding pcode,pname from .panel-heading\n",
    "            facts['panel_code'] = pcode\n",
    "            facts['panel_name'] = pname\n",
    "            \n",
    "            ## Adding tab names (Parliament or State)\n",
    "            facts['tab'] = tab_name\n",
    "            fact_data.append(facts)\n",
    "            \n",
    "            # print(len(info))\n",
    "        # print(results_by_territories)\n",
    "    # print(result_data)\n",
    "    result_df = pd.DataFrame(result_data)\n",
    "    fact_df = pd.DataFrame(fact_data)\n",
    "    # print(result_df.shape)\n",
    "    # print(result_df.columns)\n",
    "    # print(result_df.head())\n",
    "    return result_df,fact_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

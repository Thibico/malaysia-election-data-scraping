{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calonkeadilan API Scraping\n",
    "**List to Do**\n",
    "\n",
    "- [x] Click dropdown to get option values\n",
    "- [x] Scrape area names from dropdown \n",
    "- [x] Call API by using area names (small letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import libraries\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from requests_html import HTMLSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calon Keadilan | Ini Calon Kita | Kita Boleh\n",
      "Done Click!\n",
      "['johor', 'kedah', 'kelantan', 'melaka', 'negeri sembilan', 'pahang', 'pulau pinang', 'perak', 'perlis', 'sabah', 'sarawak', 'selangor', 'terengganu', 'wilayah persekutuan']\n"
     ]
    }
   ],
   "source": [
    "## Click dropdown to get ul list of area names\n",
    "## If you don't want to install & use playwright , just do uncomment and run below small_letters list block\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "small_letters = []\n",
    "async with async_playwright() as p:\n",
    "    browser = await p.chromium.launch(headless=False, slow_mo=50)\n",
    "    page = await browser.new_page()\n",
    "    await page.goto(\"https://calonkeadilan.org/\")\n",
    "    print(await page.title())\n",
    "    # await page.get_by_role(\"button\").click()\n",
    "    await page.get_by_text(\"Negeri\").click()\n",
    "    print(\"Done Click!\")\n",
    "    await page.wait_for_timeout(3000)\n",
    "    \n",
    "    ul_selector = \"ul.MuiList-root\"\n",
    "    test = await page.locator(ul_selector).inner_html()\n",
    "    data = re.findall(r'data-value=\\\"([\\w\\s]+)\\\"',test)\n",
    "    small_letters = [x.lower() for x in data[1:]]\n",
    "    # print(small_letters)\n",
    "    await page.wait_for_timeout(1000)\n",
    "    await browser.close()\n",
    "print(small_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you don't want to install & run Playwright, you can just use this block.\n",
    "## All purpose of using Playwright is to get this small_letters list to be used in API call.\n",
    "\n",
    "## Uncomment below if you've to run\n",
    "# small_letters = ['johor', 'kedah', 'kelantan', 'melaka', 'negeri sembilan', 'pahang', 'pulau pinang', 'perak', 'perlis', 'sabah', 'sarawak', 'selangor', 'terengganu', 'wilayah persekutuan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing johor\n",
      "(11, 8)\n",
      "Doing kedah\n",
      "(9, 8)\n",
      "Doing kelantan\n",
      "(6, 8)\n",
      "Doing melaka\n",
      "(2, 8)\n",
      "Doing negeri sembilan\n",
      "(3, 8)\n",
      "Doing pahang\n",
      "(23, 10)\n",
      "Doing pulau pinang\n",
      "(4, 8)\n",
      "Doing perak\n",
      "(31, 10)\n",
      "Doing perlis\n",
      "(11, 10)\n",
      "Doing sabah\n",
      "(11, 10)\n",
      "Doing sarawak\n",
      "(16, 8)\n",
      "Doing selangor\n",
      "(11, 8)\n",
      "Doing terengganu\n",
      "(4, 8)\n",
      "Doing wilayah persekutuan\n",
      "(6, 8)\n",
      "(148, 10)\n",
      "Index(['_id', 'b_pemohon', 'c_pendidikan', 'd_kerjaya', 'e_politik',\n",
      "       'kod_parlimen', 'negeri', 'parlimen', 'dun', 'kod_dun'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.DataFrame()\n",
    "appended_data = []\n",
    "for i in small_letters:\n",
    "    print(\"Doing {}\".format(i))\n",
    "    api_url = \"https://itcwu78qt3.execute-api.ap-southeast-1.amazonaws.com/dev/api/calon/view-negeri\"\n",
    "    payload = json.dumps({\n",
    "        \"negeri\" : f\"{i}\"\n",
    "    })\n",
    "    headers = {\n",
    "        'content-type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    response = requests.request(\"POST\", api_url, headers=headers, data=payload)\n",
    "    # print(response.status_code)\n",
    "    if response.status_code == 200:\n",
    "        x = response.json()\n",
    "        single_data = x['data']\n",
    "        single_df = pd.json_normalize(single_data)\n",
    "        print(single_df.shape)\n",
    "        # print(single_df.columns)\n",
    "        appended_data.append(single_df)\n",
    "    else:\n",
    "        print(\"Connection Error!\")\n",
    "raw_df = pd.concat(appended_data)\n",
    "print(raw_df.shape)\n",
    "print(raw_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### English Definitions\n",
    "\n",
    "- pemohon - Applicant\n",
    "- pendidikan - Education\n",
    "- kerjaya - Career\n",
    "- politik - Political"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create separated dataframes for Applicant, Education , Career , Political data with common _id column\n",
    "applicant_df = raw_df[['_id','b_pemohon','kod_parlimen','negeri','parlimen']].reset_index(drop=True)\n",
    "education_df = raw_df[['_id','c_pendidikan']].reset_index(drop=True)\n",
    "career_df = raw_df[['_id','d_kerjaya']].reset_index(drop=True)\n",
    "politics_df = raw_df[['_id','e_politik']].reset_index(drop=True)\n",
    "\n",
    "## Concat to create separated values by column\n",
    "pemohon_df = pd.concat([pd.DataFrame(i) for i in applicant_df['b_pemohon']], keys=applicant_df.index).reset_index(level=1, drop=True)\n",
    "pendidikan_df = pd.concat([pd.DataFrame(i) for i in education_df['c_pendidikan']], keys=education_df.index).reset_index(level=1, drop=True)\n",
    "kerjaya_df = pd.concat([pd.DataFrame(i) for i in career_df['d_kerjaya']], keys=career_df.index).reset_index(level=1, drop=True)\n",
    "politik_df = pd.concat([pd.DataFrame(i) for i in politics_df['e_politik']], keys=politics_df.index).reset_index(level=1, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148, 5)\n",
      "(148, 2)\n",
      "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
      "            ...\n",
      "            138, 139, 140, 141, 142, 143, 144, 145, 146, 147],\n",
      "           dtype='int64', length=148)\n",
      "RangeIndex(start=0, stop=148, step=1)\n"
     ]
    }
   ],
   "source": [
    "## check new dataframes\n",
    "print(applicant_df.shape)\n",
    "print(pemohon_df.shape)\n",
    "print(pemohon_df.index)\n",
    "print(applicant_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148, 6)\n",
      "(374, 5)\n",
      "(484, 5)\n",
      "(618, 5)\n"
     ]
    }
   ],
   "source": [
    "## Join column back with index\n",
    "applicant_df = applicant_df.drop('b_pemohon',axis=1).join(pemohon_df).reset_index(drop=True)\n",
    "print(applicant_df.shape)\n",
    "# print(applicant_df.columns)\n",
    "# print(applicant_df.head())\n",
    "\n",
    "education_df = education_df.drop('c_pendidikan', axis=1).join(pendidikan_df).reset_index(drop=True)\n",
    "print(education_df.shape)\n",
    "career_df = career_df.drop('d_kerjaya', axis=1).join(kerjaya_df).reset_index(drop=True)\n",
    "print(career_df.shape)\n",
    "politics_df = politics_df.drop('e_politik', axis=1).join(politik_df).reset_index(drop=True)\n",
    "print(politics_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Decided to export CSV to be align with other scraped dataset\n",
    "applicant_df.to_csv('./data/raw/calonkeadilan/applicant.csv', encoding='utf-8')\n",
    "education_df.to_csv('./data/raw/calonkeadilan/education.csv', encoding='utf-8')\n",
    "career_df.to_csv('./data/raw/calonkeadilan/career.csv', encoding='utf-8')\n",
    "politics_df.to_csv('./data/raw/calonkeadilan/politics.csv',encoding='utf-8')\n",
    "\n",
    "## Test with Excel\n",
    "# applicant_df.to_excel('./data/raw/calonkeadilan/applicant.xlsx')\n",
    "\n",
    "## Export JSON >> raw/calonkeadilan folder\n",
    "# applicant_df.to_json('./data/raw/calonkeadilan/applicant.json', orient='index')\n",
    "# applicant_df.to_json('./data/raw/calonkeadilan/applicant_compared.json', orient='records')\n",
    "# result = applicant_df.to_json(orient='index')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d28bb1bd1ce1077ff7173964964158d753f525bcf2f97fda0113d83669db9a2b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 ('environment': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

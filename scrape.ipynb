{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import required libraries\n",
    "import re\n",
    "import pandas as pd\n",
    "from requests_html import HTMLSession\n",
    "from requests_html import AsyncHTMLSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_url = \"https://election.thestar.com.my/\"\n",
    "session = HTMLSession()\n",
    "r = session.get(main_url)\n",
    "\n",
    "## Previous testing individually\n",
    "# r = session.get('https://election.thestar.com.my/ft.html')\n",
    "# r = session.get('https://election.thestar.com.my/johor.html')\n",
    "# r = session.get('https://election.thestar.com.my/kelantan.html')\n",
    "# r = session.get('https://election.thestar.com.my/perak.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scraping svg\n",
    "## We need to use asynchronous function because map svg is rendered by js\n",
    "async def get_svg(url: str,region):\n",
    "    asession = AsyncHTMLSession()\n",
    "    r = await asession.get(url)\n",
    "    await r.html.arender(sleep=5)\n",
    "    tab_content = r.html.find(\".tab-content\",first=True)\n",
    "    tab_panels = tab_content.find(\".tab-pane\")\n",
    "    print(\"Length of tab_panels: \",len(tab_panels))\n",
    "    for a in range(len(tab_panels)):\n",
    "        tab_attributes = tab_panels[a].attrs\n",
    "        tab_id = tab_attributes.get(\"id\")\n",
    "        if tab_id == 'f1':\n",
    "            tab_name = \"parliament\"\n",
    "            svg_data = tab_panels[0].find(\"#svgP\",first=True).html\n",
    "            # print(type(svg_data))\n",
    "            if svg_data != None:\n",
    "                ## Convert string into byte \n",
    "                svg_byte = bytes(svg_data, encoding=\"utf-8\")\n",
    "                given_name = region + \"_\" + tab_name\n",
    "                with open(f'./svgs/{given_name}.svg', 'wb+') as f:\n",
    "                    f.write(svg_byte)\n",
    "                print(f\"{given_name} svg write!\")\n",
    "            else:\n",
    "                print(\"Not found svg for Parliment\")\n",
    "            \n",
    "        if tab_id =='f2':\n",
    "            tab_name = \"state\"\n",
    "            svg_data = tab_panels[1].find(\"#svgN\", first=True).html\n",
    "            if svg_data != None:\n",
    "                ## Convert string into byte \n",
    "                svg_byte = bytes(svg_data, encoding=\"utf-8\")\n",
    "                given_name = region + \"_\" + tab_name\n",
    "                with open(f'./svgs/{given_name}.svg', 'wb+') as f:\n",
    "                    f.write(svg_byte)\n",
    "                print(f\"{given_name} svg write!\")\n",
    "            else:\n",
    "                print(\"Not found svgN for State\")\n",
    "    await asession.close()\n",
    "    # return svg_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "## testing with one url\n",
    "test_url = \"https://election.thestar.com.my/johor.html\"\n",
    "await get_svg(test_url,'Johor')\n",
    "'''\n",
    "'''\n",
    "## Testing block to convert string to bytes\n",
    "#convert string to byte\n",
    "svg_byte = bytes(data_web, \"utf-8\")\n",
    "with open('test.svg','wb+') as f:\n",
    "    f.write(svg_byte)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FederalTerritories | https://election.thestar.com.my/ft.html\n",
      "Length of tab_panels:  1\n",
      "<class 'str'>\n",
      "FederalTerritories_parliament svg write!\n",
      "Scraping SVG for FederalTerritories done!\n",
      "Johor | https://election.thestar.com.my/johor.html\n",
      "Length of tab_panels:  2\n",
      "<class 'str'>\n",
      "Johor_parliament svg write!\n",
      "Johor_state svg write!\n",
      "Scraping SVG for Johor done!\n",
      "Kedah | https://election.thestar.com.my/kedah.html\n",
      "Length of tab_panels:  2\n",
      "<class 'str'>\n",
      "Kedah_parliament svg write!\n",
      "Kedah_state svg write!\n",
      "Scraping SVG for Kedah done!\n",
      "Kelantan | https://election.thestar.com.my/kelantan.html\n",
      "Length of tab_panels:  2\n",
      "<class 'str'>\n",
      "Kelantan_parliament svg write!\n",
      "Kelantan_state svg write!\n",
      "Scraping SVG for Kelantan done!\n",
      "Melaka | https://election.thestar.com.my/malacca.html\n",
      "Length of tab_panels:  2\n",
      "<class 'str'>\n",
      "Melaka_parliament svg write!\n",
      "Melaka_state svg write!\n",
      "Scraping SVG for Melaka done!\n",
      "NegriSembilan | https://election.thestar.com.my/negerisembilan.html\n",
      "Length of tab_panels:  2\n",
      "<class 'str'>\n",
      "NegriSembilan_parliament svg write!\n",
      "NegriSembilan_state svg write!\n",
      "Scraping SVG for NegriSembilan done!\n",
      "Pahang | https://election.thestar.com.my/pahang.html\n",
      "Length of tab_panels:  2\n",
      "<class 'str'>\n",
      "Pahang_parliament svg write!\n",
      "Pahang_state svg write!\n",
      "Scraping SVG for Pahang done!\n",
      "Penang | https://election.thestar.com.my/penang.html\n",
      "Length of tab_panels:  2\n",
      "<class 'str'>\n",
      "Penang_parliament svg write!\n",
      "Penang_state svg write!\n",
      "Scraping SVG for Penang done!\n",
      "Perak | https://election.thestar.com.my/perak.html\n",
      "Length of tab_panels:  2\n",
      "<class 'str'>\n",
      "Perak_parliament svg write!\n",
      "Perak_state svg write!\n",
      "Scraping SVG for Perak done!\n",
      "Perlis | https://election.thestar.com.my/perlis.html\n",
      "Length of tab_panels:  2\n",
      "<class 'str'>\n",
      "Perlis_parliament svg write!\n",
      "Perlis_state svg write!\n",
      "Scraping SVG for Perlis done!\n",
      "Sabah | https://election.thestar.com.my/sabah.html\n",
      "Length of tab_panels:  2\n",
      "<class 'str'>\n",
      "Sabah_parliament svg write!\n",
      "Sabah_state svg write!\n",
      "Scraping SVG for Sabah done!\n",
      "Sarawak | https://election.thestar.com.my/sarawak.html\n",
      "Length of tab_panels:  1\n",
      "<class 'str'>\n",
      "Sarawak_parliament svg write!\n",
      "Scraping SVG for Sarawak done!\n",
      "Selangor | https://election.thestar.com.my/selangor.html\n",
      "Length of tab_panels:  2\n",
      "<class 'str'>\n",
      "Selangor_parliament svg write!\n",
      "Selangor_state svg write!\n",
      "Scraping SVG for Selangor done!\n",
      "Terengganu | https://election.thestar.com.my/terengganu.html\n",
      "Length of tab_panels:  2\n",
      "<class 'str'>\n",
      "Terengganu_parliament svg write!\n",
      "Terengganu_state svg write!\n",
      "Scraping SVG for Terengganu done!\n",
      "PinnedSeats | https://election.thestar.com.my/pinned.html\n",
      "Length of tab_panels:  1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# print(ns.url)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# print(ns.status_code)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ns\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m## saving svg files for each parliment & state map\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m get_svg(urls,state_name)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScraping SVG for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstate_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m done!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m## scraping results & facts(demographic) data\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# scrape_panels(ns, state_name)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn [11], line 15\u001b[0m, in \u001b[0;36mget_svg\u001b[0;34m(url, region)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tab_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     14\u001b[0m     tab_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparliament\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 15\u001b[0m     svg_data \u001b[38;5;241m=\u001b[39m \u001b[43mtab_panels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m#svgP\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhtml\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(svg_data))\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m svg_data \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;66;03m## Convert string into byte \u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'html'"
     ]
    }
   ],
   "source": [
    "## Scraping data for looping webpages\n",
    "state = r.html.find(\"ul.state-list\", first=True)\n",
    "state_list = state.find(\"a\")\n",
    "for i in range(len(state_list)):\n",
    "    list_attrs = state_list[i].attrs\n",
    "    # print(list_attrs)\n",
    "    urls = main_url + list_attrs.get('href')\n",
    "    state_name = state_list[i].text.replace(\" \",\"\")\n",
    "    print(state_name,\"|\",urls)\n",
    "    new_session = HTMLSession()\n",
    "    ns = new_session.get(urls)\n",
    "    # print(ns.url)\n",
    "    # print(ns.status_code)\n",
    "    if ns.status_code == 200:\n",
    "        ## saving svg files for each parliment & state map\n",
    "        await get_svg(urls,state_name)\n",
    "        print(f\"Scraping SVG for {state_name} done!\")\n",
    "        \n",
    "        ## scraping results & facts(demographic) data\n",
    "        # scrape_panels(ns, state_name)\n",
    "    else:\n",
    "        print(\"Connection error!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Scraping function to get results & demographic data\n",
    "def scrape_panels(conn, region):\n",
    "    tab_content = conn.html.find(\".tab-content\")\n",
    "    \n",
    "    ## Only ft & sarawak pages will have one tab_panel , others length will be 2\n",
    "    tab_panels = tab_content[0].find(\".tab-pane\")\n",
    "    # print(\"Tab Panels (P or S):{}\".format(len(tab_panels)))\n",
    "    for a in range(len(tab_panels)):\n",
    "        ## Divide parliament or state tabs\n",
    "        tab_attributes = tab_panels[a].attrs\n",
    "        tab_id = tab_attributes.get(\"id\")\n",
    "        if tab_id == 'f1':\n",
    "            tab_name = \"parliament\"\n",
    "            \n",
    "            ## Getting Parliament > Result , Parliament > Facts(demographic)\n",
    "            p_result,p_fact = scrape_data(tab_panels[0],tab_name)\n",
    "            p_result['state_region'] = region\n",
    "            p_fact['state_region'] = region\n",
    "            \n",
    "            ## should I export csv under this function?\n",
    "            ## Export with custom name\n",
    "            given_name = region + \"_\" + tab_name\n",
    "            p_result.to_csv(f'./data/{given_name}_result.csv')\n",
    "            p_fact.to_csv(f'./data/{given_name}_fact.csv')\n",
    "            \n",
    "        if tab_id == 'f2':\n",
    "            tab_name = \"state\"\n",
    "       \n",
    "            ## Getting State > Result , State > Facts(demographic)\n",
    "            s_result,s_fact = scrape_data(tab_panels[1],tab_name)\n",
    "            s_result['state_region'] = region\n",
    "            s_fact['state_region'] = region\n",
    "            \n",
    "            ## Export with custom name\n",
    "            given_name = region + \"_\" + tab_name\n",
    "            s_result.to_csv(f'./data/{given_name}_result.csv')\n",
    "            s_fact.to_csv(f'./data/{given_name}_fact.csv')\n",
    "        # print(tab_name)\n",
    "        # print(f\"Tab-Panel-{a}\")\n",
    "        # print(\"---xxx---\")\n",
    "        \n",
    "    ## If I exported CSVs , I don't need to return dfs.\n",
    "    if len(tab_panels) == 1:\n",
    "        ## Returning parliament result & facts(demographic) data\n",
    "        print(\"Parliament only data\")\n",
    "        # return p_result,p_fact\n",
    "    elif len(tab_panels) == 2:\n",
    "        ## Returning both perliment+state result & facts(demographic) data\n",
    "        print(\"Parliament + State data\")\n",
    "        # return p_result,p_fact,s_result,s_fact\n",
    "    else:\n",
    "        print(\"No Data found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_data(tab_panel,tab_name):\n",
    "    ## scrape data under .winner-list > multiple .panel\n",
    "    panels = tab_panel.find(\".panel\")\n",
    "    # print(len(panels))\n",
    "    result_data = []\n",
    "    fact_data = []\n",
    "        \n",
    "    for i in range(len(panels)):\n",
    "        ## Inside .panel-heading\n",
    "        header = panels[i].find(\"h4.panel-title\")[0].text.split(\" \")\n",
    "        pcode = header[0]\n",
    "        pname = ' '.join(header[1:])\n",
    "        print(pcode,\"|\",pname)\n",
    "        \n",
    "        ## Inside .panel-body \n",
    "        wrapper = panels[i].find(\".progress-wrapper\")\n",
    "        # print(len(wrapper))\n",
    "        # print(\"---xx---\")\n",
    "        \n",
    "        for j in range(len(wrapper)):\n",
    "            results_by_territories = {}\n",
    "            name = wrapper[j].find(\"p.name-candidate\")[0].text\n",
    "            # print(name)\n",
    "            number_of_voters = wrapper[j].find(\".number-of-voters\")[0].text\n",
    "            # print(number_of_voters)\n",
    "            results_by_territories[\"name\"] = name\n",
    "            results_by_territories[\"number_of_voters\"] = number_of_voters\n",
    "            \n",
    "            ## Adding pcode,pname from .panel-heading\n",
    "            results_by_territories[\"panel_code\"]= pcode\n",
    "            results_by_territories[\"panel_name\"]= pname\n",
    "            \n",
    "            ## Adding tab name (Parliament or State)\n",
    "            results_by_territories[\"tab\"] = tab_name\n",
    "            result_data.append(results_by_territories)\n",
    "        \n",
    "        \n",
    "        blue_box = panels[i].find(\".blue-box-info\")\n",
    "        \n",
    "        facts = {}\n",
    "        if blue_box != None:\n",
    "            # print(\"Found Blue_box!\")\n",
    "            ## Do I need to find \"voters-vote\" class?\n",
    "            info = blue_box[0].find(\"p\")\n",
    "            num_regex = re.compile(r'[\\d,\\.\\s\\(%\\)]+')\n",
    "            registered_voters = ''.join(num_regex.findall(info[0].text)).strip()\n",
    "            majority = ''.join(num_regex.findall(info[1].text)).strip()\n",
    "            spoilt_votes = ''.join(num_regex.findall(info[2].text)).strip()\n",
    "            unreturned_votes = ''.join(num_regex.findall(info[3].text)).strip()\n",
    "            voter_turnout = ''.join(num_regex.findall(info[4].text)).strip()\n",
    "            demographics = info[5].text\n",
    "            # print(registered_voters,\"|\",majority,\"|\",spoilt_votes,\"|\",unreturned_votes,\"|\",voter_turnout)\n",
    "            # print(demographics)\n",
    "    \n",
    "            facts['registered_voters'] = registered_voters\n",
    "            facts['majority'] = majority\n",
    "            facts['spoilt_votes'] = spoilt_votes\n",
    "            facts['unreturned_votes']= unreturned_votes\n",
    "            facts['voter_turnout'] = voter_turnout\n",
    "            facts['demographics']= demographics\n",
    "            \n",
    "            ## Adding pcode,pname from .panel-heading\n",
    "            facts['panel_code'] = pcode\n",
    "            facts['panel_name'] = pname\n",
    "            \n",
    "            ## Adding tab names (Parliament or State)\n",
    "            facts['tab'] = tab_name\n",
    "            fact_data.append(facts)\n",
    "            \n",
    "            # print(len(info))\n",
    "        # print(results_by_territories)\n",
    "    # print(result_data)\n",
    "    result_df = pd.DataFrame(result_data)\n",
    "    fact_df = pd.DataFrame(fact_data)\n",
    "    # print(result_df.shape)\n",
    "    # print(result_df.columns)\n",
    "    # print(result_df.head())\n",
    "    return result_df,fact_df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43f9f978e86097f86422ad3a1a736eb79d02874e31223e758cffd1f02c507dc9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('environment': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
